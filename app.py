# -*- coding: utf-8 -*-
"""Image_captioning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aTRLv-po0LKXUmt28N6vTiI7TGBGUiqo
"""

# !pip install transformers

# !pip install gradio

import torch
from PIL import Image
from transformers import VisionEncoderDecoderModel,ViTFeatureExtractor, AutoTokenizer
import requests

model = VisionEncoderDecoderModel.from_pretrained("nlpconnect/vit-gpt2-image-captioning")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

vit_feature_extractor = ViTFeatureExtractor.from_pretrained("nlpconnect/vit-gpt2-image-captioning")

tokenizer = AutoTokenizer.from_pretrained("nlpconnect/vit-gpt2-image-captioning")

# url = "https://tinypng.com/images/social/website.jpg"

# img=[]
# import io
# r = requests.get(url,stream=True)
# aux_img = Image.open(io.BytesIO(r.content))
# aux_img

# pixel_values = vit_feature_extractor(images=aux_img, return_tensors="pt").pixel_values
# pixel_values = pixel_values.to(device)

max_len = 16
num_beams = 5
gen_kwargs = {"max_length":max_len, "num_beams":num_beams}

# out_ids = model.generate(pixel_values,**gen_kwargs)
# preds = tokenizer.batch_decode(out_ids,skip_special_tokens=True)
# preds

#inference function

def image_captioning (img):
  pixel_values=vit_feature_extractor(images=img, return_tensors = "pt").pixel_values
  pixel_values=pixel_values.to(device)
  output_ids = model.generate(pixel_values,**gen_kwargs)
  preds = tokenizer.batch_decode(output_ids,skip_special_tokens = True)
  return preds

import gradio as gr

inputs = [
    gr.inputs.Image(type="pil", label="Uploaded Image")
]

outputs = [
    gr.outputs.Textbox(label="Caption")
]

title = "Image Captioning Using Hugging face pretrained models"
description = "It uses ViT and GPT2 to generate captions for images that are uploaded. COCO dataset is used for training this model. So, there can be baises in the generation of captions like based on gender or races"
examples=["img1.jpg","img2.jpg"]

gr.Interface(
    image_captioning,
    inputs,
    outputs,
    title=title,
    description=description,
    examples=examples,
    theme="higgingface"
).launch(debug=True,enable_queue=True)

